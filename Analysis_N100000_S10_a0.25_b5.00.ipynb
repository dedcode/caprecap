{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (array([0.59868766, 0.04459026, 0.04459026, 0.04459026, 0.04459026,\n",
    "        0.04459026, 0.04459026, 0.04459026, 0.04459026, 0.04459026]),\n",
    "     array([0.4291727, 0.4291727, 0.4291727, 0.4291727, 0.4291727, 0.4291727,\n",
    "        0.4291727, 0.4291727, 0.4291727, 0.4291727]))\n",
    "        \n",
    "    38626.173 /  0.467 /  9.179 /  0.599 /  0.429 / 122301.308: 100%|██████████| 5000/5000 [17:18<00:00,  4.82it/s]\n",
    "\n",
    "\n",
    "    Total Unseen: 88390 / Likelihood: -20163.0111\n",
    "\n",
    "\n",
    "    Total Unseen: 88000 / Likelihood: -20162.9154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sjfvgkwcpbgo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ded/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from theano import shared\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "from pymc3.distributions.transforms import t_stick_breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9gBE6uf1Je0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12276, int)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data/gch-100000-10-0.25-5.00.pkl', 'rb') as f:\n",
    "  GCH, TH = pickle.load(f)\n",
    "S = 10\n",
    "npdata = np.array(GCH, dtype = int)\n",
    "V = len(GCH)\n",
    "V, type(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FdWYAnbqTsy"
   },
   "outputs": [],
   "source": [
    "def get_vmask():\n",
    "    v_mask = np.zeros([S,S,S])\n",
    "    for s in np.arange(S):\n",
    "        for q in np.arange(s,S):\n",
    "            c1 = np.zeros(s)\n",
    "            c2 = np.ones(q-s)\n",
    "            c3 = np.zeros(S-q)\n",
    "            v_mask[s,q]= np.concatenate((c1, c2, c3))\n",
    "    return tt.constant(v_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy3gIbwRqTs0"
   },
   "outputs": [],
   "source": [
    "def get_imask():\n",
    "    s_mask = np.zeros([V,S])\n",
    "    q_mask = np.zeros([V,S])\n",
    "    for w in np.arange(V):\n",
    "        f, l = npdata[w, 0] , npdata[w, 1]\n",
    "        s_mask[w] = np.concatenate((np.ones(f+1), np.zeros(S - f -1)))\n",
    "        q_mask[w] = np.concatenate((np.zeros(l), np.ones(S-l)))\n",
    "    i_mask = np.einsum(\"is,iq->isq\", s_mask, q_mask)\n",
    "    return tt.constant(i_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FoNaVSVwqTs3"
   },
   "outputs": [],
   "source": [
    "def get_Risq(a,b):\n",
    "    tmp_u = npdata[:, 2]\n",
    "    expanded_u = tmp_u[:, np.newaxis, np.newaxis] *  np.ones((V, S, S)) # V x S x S\n",
    "    d = np.broadcast_to(np.triu(np.ones([S,S]), 0).cumsum(axis =1), (V, S, S)) # V x S x S\n",
    "    n = tt.constant(np.clip(d,a_min=0,a_max=S+1))\n",
    "    n_u = np.triu(d - expanded_u, 0)\n",
    "    n_u = tt.constant(np.clip(n_u,a_min=0,a_max=max(tmp_u))) # V x S x S\n",
    "   \n",
    "    \n",
    "    # The beta binomial\n",
    "    R_isq =   tt.gammaln(n+1)\n",
    "    R_isq -=  tt.gammaln(expanded_u+1)\n",
    "    R_isq -=  tt.gammaln(n_u+1)   \n",
    "    R_isq +=  tt.gammaln(expanded_u+a)\n",
    "    R_isq +=  tt.gammaln(n_u+b)\n",
    "    R_isq -=  tt.gammaln(n+a+b)\n",
    "    R_isq +=  tt.gammaln(a+b) - tt.gammaln(a) - tt.gammaln(b)\n",
    "\n",
    "    # The above is the computation of the log, so we take the exponent\n",
    "    return tt.exp(R_isq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6kPTSl-BqTs5"
   },
   "outputs": [],
   "source": [
    "def get_Risq0(a,b):\n",
    "    # n = q - s + 1\n",
    "    n = tt.constant(np.triu(np.ones([S,S]), 0).cumsum(axis =1))\n",
    "    R0_sq = tt.gammaln(n + b) - tt.gammaln(n + a + b) + tt.gammaln(a + b) - tt.gammaln(b)\n",
    "    return tt.exp(R0_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yXnG7rkqTs6"
   },
   "outputs": [],
   "source": [
    "def logp_capture(arr, phi, a, b, U):\n",
    "    def ll_capture_f(mycaptures):\n",
    "        \n",
    "        # Masks: try to compute these once.\n",
    "        phi_mask = get_vmask()  # S x S x S . all possible arrivals and departures for the \"SURVIVAL\"\n",
    "        i_mask   = get_imask()  # KxK   . matrix with real possible arrival and departures\n",
    "        R_isq = get_Risq(a, b) #\n",
    "        R0_sq = get_Risq0(a, b) #\n",
    "        \n",
    "        # Likelihood of Capture Li\n",
    "        phi_v = tt.pow(1-phi, phi_mask)\n",
    "        phi_v = tt.prod(phi_v, axis=2)\n",
    "        LD = arr[:, np.newaxis] * phi_v * phi\n",
    "        LD_isq = tt.mul(LD, i_mask)\n",
    "        Li = tt.batched_tensordot(LD_isq, R_isq, axes = 2)\n",
    "        \n",
    "        # Likelihood of No-Capture L0\n",
    "        v0_mask = 1 - phi_mask[0] # tihs is reuse\n",
    "        LD0 = tt.mul(LD, v0_mask)\n",
    "        L0 = tt.sum(LD0 * R0_sq)\n",
    "        \n",
    "        # Multinomial\n",
    "        obj1 = tt.gammaln(tt.constant(V)+U+1.0) - tt.gammaln(U+1.0) - tt.gammaln(tt.constant(V)+ 1.0) #\n",
    "        obj2 = tt.sum(tt.log(Li))\n",
    "        obj3 = U * tt.log(L0)\n",
    "\n",
    "        objective = obj1 + obj2 + obj3 \n",
    "        \n",
    "        return objective\n",
    "    \n",
    "    return ll_capture_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#birth_init, dep = (np.array([0.4       , 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
    "#          0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667]),\n",
    "# np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1. ]))\n",
    "#for UU in range(87600, 88400, 10):\n",
    "#    print(\"Total Unseen:\", UU, \"/ Likelihood:\", logp_capture(birth_init, dep, .25,  5., UU)(npdata).eval().round(4))\n",
    "#print(\"Total Unseen:\", UU, \"/ Likelihood:\", logp_capture(birth_init, dep, .25,  5., 100000-V)(npdata).eval().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pATM9j8cqTs8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ded/anaconda3/lib/python3.6/site-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n"
     ]
    }
   ],
   "source": [
    "# custom log-liklihood\n",
    "# model\n",
    "with pm.Model() as model:\n",
    "    # parameters\n",
    "    U = pm.DiscreteUniform('Unseen', lower=V, upper=10*V)\n",
    "    a = pm.Uniform('alpha', .1, .3)\n",
    "    b = pm.Uniform('beta', 4., 6.)\n",
    "    phi    = pm.Uniform('departure', 0.1, 1., shape=S)\n",
    "    arr    = pm.Dirichlet('arrival', a=np.array([1./S]*S), shape=S)\n",
    "    \n",
    "    # Model Log-likelihood\n",
    "    ob = pm.DensityDist('x', logp_capture(arr, phi, a, b, U), observed=npdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Ands2YCRqTs9",
    "outputId": "450d1a59-20e5-479a-852e-b4dd19fe3944"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequential sampling (2 chains in 1 job)\n",
      "CompoundStep\n",
      ">Metropolis: [Unseen]\n",
      ">NUTS: [arrival, departure, beta, alpha]\n",
      "100%|██████████| 1500/1500 [1:04:00<00:00,  2.56s/it]\n",
      "100%|██████████| 1500/1500 [08:05<00:00,  3.09it/s]\n",
      "There were 168 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 1668 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.33156138536892693, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "  #posterior = pm.sample(3, tune=0, chains=1, progressbar=False)\n",
    "  #step = pm.NUTS()\n",
    "  #posterior = pm.sample(100000, step=step, njobs = 4)\n",
    "  posterior = pm.sample(1000, cores = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for RV in model.basic_RVs:\n",
    "    print(RV.name, RV.logp(model.test_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "VqwQlHMuoCxd",
    "outputId": "d31f05b8-723a-4f38-9c02-9b89baec9709"
   },
   "outputs": [],
   "source": [
    "pm.energyplot(posterior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1358
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507,
     "status": "error",
     "timestamp": 1537418913125,
     "user": {
      "displayName": "Djellel Difallah",
      "photoUrl": "//lh5.googleusercontent.com/-t5fU7F-dQI8/AAAAAAAAAAI/AAAAAAAAGMw/kTaNXtXJ1J4/s50-c-k-no/photo.jpg",
      "userId": "109856363840473722295"
     },
     "user_tz": 240
    },
    "id": "Fgt-4TxQqTtB",
    "outputId": "50c2838c-7b20-4301-faf3-9f1ce1e14265"
   },
   "outputs": [],
   "source": [
    "pm.traceplot(posterior);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 162,
     "status": "error",
     "timestamp": 1537418916554,
     "user": {
      "displayName": "Djellel Difallah",
      "photoUrl": "//lh5.googleusercontent.com/-t5fU7F-dQI8/AAAAAAAAAAI/AAAAAAAAGMw/kTaNXtXJ1J4/s50-c-k-no/photo.jpg",
      "userId": "109856363840473722295"
     },
     "user_tz": 240
    },
    "id": "EUY8a4Qu0cJq",
    "outputId": "bfcbf371-c091-4a7f-a188-5ad3850e9bc1"
   },
   "outputs": [],
   "source": [
    "pm.summary(posterior).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['Unseen'].logp(model.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['a'].logp(model.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Posterior_last.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
